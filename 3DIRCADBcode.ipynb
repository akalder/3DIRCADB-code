{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "from sklearn.utils import shuffle\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, ReduceLROnPlateau, EarlyStopping, TensorBoard\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.utils import CustomObjectScope\n",
        "from sklearn.metrics import f1_score, jaccard_score, precision_score, recall_score\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "eCmFFDeOTK2Y"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BkobzRLTO2f",
        "outputId": "a4976d73-99fd-4610-f3bd-00b7d9503502"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading data and splitting into train, test and validation"
      ],
      "metadata": {
        "id": "uqNmOZtZTXvX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "H = 256\n",
        "W = 256\n",
        "\n",
        "def create_dir(path):\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "\n",
        "def load_dataset(path, split=0.2):\n",
        "    images = sorted(glob(os.path.join(path, \"CT_Images\", \"*.jpg\")))\n",
        "    masks = sorted(glob(os.path.join(path, \"Labelled_Masks\", \"*.jpg\")))\n",
        "\n",
        "    split_size = int(len(images) * split)\n",
        "\n",
        "    train_x, valid_x = train_test_split(images, test_size=split_size, random_state=42)\n",
        "    train_y, valid_y = train_test_split(masks, test_size=split_size, random_state=42)\n",
        "\n",
        "    train_x, test_x = train_test_split(train_x, test_size=split_size, random_state=42)\n",
        "    train_y, test_y = train_test_split(train_y, test_size=split_size, random_state=42)\n",
        "\n",
        "    return (train_x, train_y), (valid_x, valid_y), (test_x, test_y)\n",
        "\n",
        "\n",
        "def read_image(path):\n",
        "    path = path.decode()\n",
        "    x = cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "    x = cv2.resize(x, (W, H))\n",
        "    x = x / 255.0\n",
        "    x = x.astype(np.float32)\n",
        "    return x\n",
        "\n",
        "def read_mask(path):\n",
        "    path = path.decode()\n",
        "    x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)  ## (h, w)\n",
        "    x = cv2.resize(x, (W, H))   ## (h, w)\n",
        "    x = x / 255.0               ## (h, w)\n",
        "    x = x.astype(np.float32)    ## (h, w)\n",
        "    x = np.expand_dims(x, axis=-1)## (h, w, 1)\n",
        "    return x\n",
        "\n",
        "def tf_parse(x, y):\n",
        "    def _parse(x, y):\n",
        "        x = read_image(x)\n",
        "        y = read_mask(y)\n",
        "        return x, y\n",
        "\n",
        "    x, y = tf.numpy_function(_parse, [x, y], [tf.float32, tf.float32])\n",
        "    x.set_shape([H, W, 3])\n",
        "    y.set_shape([H, W, 1])\n",
        "    return x, y\n",
        "\n",
        "def tf_dataset(X, Y, batch=2):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((X, Y))\n",
        "    dataset = dataset.map(tf_parse)\n",
        "    dataset = dataset.batch(batch)\n",
        "    dataset = dataset.prefetch(10)\n",
        "    return dataset\n",
        "\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\"\"\" Directory for storing files \"\"\"\n",
        "create_dir(\"files\")\n",
        "\n",
        "\"\"\" Hyperparameters \"\"\"\n",
        "batch_size = 2\n",
        "lr = 1e-4\n",
        "num_epochs = 50\n",
        "model_path = os.path.join(\"files\", \"model.h5\")\n",
        "csv_path = os.path.join(\"files\", \"log.csv\")\n",
        "\n",
        "\"\"\" Dataset \"\"\"\n",
        "# dataset_path = \"F:/JU PROJECTS/LiverDatasets/3DIRCADB manual\"\n",
        "dataset_path = \"/content/drive/MyDrive/3DIRCADB manual\"\n",
        "(train_x, train_y), (valid_x, valid_y), (test_x, test_y) = load_dataset(dataset_path)\n",
        "\n",
        "print(f\"Train: {len(train_x)} - {len(train_y)}\")\n",
        "print(f\"Valid: {len(valid_x)} - {len(valid_y)}\")\n",
        "print(f\"Test : {len(test_x)} - {len(test_y)}\")\n",
        "\n",
        "train_dataset = tf_dataset(train_x, train_y, batch=batch_size)\n",
        "valid_dataset = tf_dataset(valid_x, valid_y, batch=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99_zrH3NTWEQ",
        "outputId": "83cc6273-d7b6-4a08-8693-3f838c66d0c3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 1695 - 1695\n",
            "Valid: 564 - 564\n",
            "Test : 564 - 564\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metrics"
      ],
      "metadata": {
        "id": "YDFhBLtQUEGf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "smooth = 1e-15\n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true = tf.keras.layers.Flatten()(y_true)\n",
        "    y_pred = tf.keras.layers.Flatten()(y_pred)\n",
        "    intersection = tf.reduce_sum(y_true * y_pred)\n",
        "    return (2. * intersection + smooth) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + smooth)\n",
        "\n",
        "def dice_loss(y_true, y_pred):\n",
        "    return 1.0 - dice_coef(y_true, y_pred)"
      ],
      "metadata": {
        "id": "JC8Hae4uUFg6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model"
      ],
      "metadata": {
        "id": "Jg4OmMhwUI3K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_block(inputs, num_filters):\n",
        "    x = Conv2D(num_filters, 3, padding=\"same\")(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "def encoder_block(inputs, num_filters):\n",
        "    x = conv_block(inputs, num_filters)\n",
        "    p = MaxPool2D((2, 2))(x)\n",
        "    return x, p\n",
        "\n",
        "def decoder_block(inputs, skip_features, num_filters):\n",
        "    x = Conv2DTranspose(num_filters, 2, strides=2, padding=\"same\")(inputs)\n",
        "    x = Concatenate()([x, skip_features])\n",
        "    x = conv_block(x, num_filters)\n",
        "    return x\n",
        "\n",
        "def build_unet(input_shape):\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    s1, p1 = encoder_block(inputs, 64)\n",
        "    s2, p2 = encoder_block(p1, 128)\n",
        "    s3, p3 = encoder_block(p2, 256)\n",
        "    s4, p4 = encoder_block(p3, 512)\n",
        "\n",
        "\n",
        "    b1 = conv_block(p4, 1024)\n",
        "\n",
        "    d1 = decoder_block(b1, s4, 512)\n",
        "    d2 = decoder_block(d1, s3, 256)\n",
        "    d3 = decoder_block(d2, s2, 128)\n",
        "    d4 = decoder_block(d3, s1, 64)\n",
        "\n",
        "    outputs = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(d4)\n",
        "\n",
        "    model = Model(inputs, outputs, name=\"UNET\")\n",
        "    return model\n",
        "\n",
        "model = build_unet((H, W, 3))\n",
        "model.compile(loss=dice_loss, optimizer=Adam(lr), metrics=[dice_coef])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ar6saw22UIQr",
        "outputId": "8344892c-0c7f-43e9-cef2-072c00879ddd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"UNET\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 256, 256, 64  1792        ['input_1[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 256, 256, 64  256        ['conv2d[0][0]']                 \n",
            " alization)                     )                                                                 \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 256, 256, 64  0           ['batch_normalization[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 256, 256, 64  36928       ['activation[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 256, 256, 64  256        ['conv2d_1[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 256, 256, 64  0           ['batch_normalization_1[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 128, 128, 64  0           ['activation_1[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 128, 128, 12  73856       ['max_pooling2d[0][0]']          \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 128, 128, 12  512        ['conv2d_2[0][0]']               \n",
            " rmalization)                   8)                                                                \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 128, 128, 12  0           ['batch_normalization_2[0][0]']  \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 128, 128, 12  147584      ['activation_2[0][0]']           \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 128, 128, 12  512        ['conv2d_3[0][0]']               \n",
            " rmalization)                   8)                                                                \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 128, 128, 12  0           ['batch_normalization_3[0][0]']  \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 128)  0          ['activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 64, 64, 256)  295168      ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 64, 64, 256)  1024       ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 64, 64, 256)  0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 64, 64, 256)  590080      ['activation_4[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 64, 64, 256)  1024       ['conv2d_5[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 64, 64, 256)  0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 256)  0          ['activation_5[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 32, 32, 512)  1180160     ['max_pooling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 32, 32, 512)  2048       ['conv2d_6[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 32, 32, 512)  0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 32, 32, 512)  2359808     ['activation_6[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 32, 32, 512)  2048       ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 32, 32, 512)  0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 512)  0          ['activation_7[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 16, 16, 1024  4719616     ['max_pooling2d_3[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 16, 16, 1024  4096       ['conv2d_8[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 16, 16, 1024  0           ['batch_normalization_8[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 16, 16, 1024  9438208     ['activation_8[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 16, 16, 1024  4096       ['conv2d_9[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 16, 16, 1024  0           ['batch_normalization_9[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_transpose (Conv2DTransp  (None, 32, 32, 512)  2097664    ['activation_9[0][0]']           \n",
            " ose)                                                                                             \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 32, 32, 1024  0           ['conv2d_transpose[0][0]',       \n",
            "                                )                                 'activation_7[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 32, 32, 512)  4719104     ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 32, 32, 512)  2048       ['conv2d_10[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 32, 32, 512)  0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 32, 32, 512)  2359808     ['activation_10[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 32, 32, 512)  2048       ['conv2d_11[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 32, 32, 512)  0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_transpose_1 (Conv2DTran  (None, 64, 64, 256)  524544     ['activation_11[0][0]']          \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 64, 64, 512)  0           ['conv2d_transpose_1[0][0]',     \n",
            "                                                                  'activation_5[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 64, 64, 256)  1179904     ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 64, 64, 256)  1024       ['conv2d_12[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 64, 64, 256)  0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 64, 64, 256)  590080      ['activation_12[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 64, 64, 256)  1024       ['conv2d_13[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 64, 64, 256)  0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_transpose_2 (Conv2DTran  (None, 128, 128, 12  131200     ['activation_13[0][0]']          \n",
            " spose)                         8)                                                                \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 128, 128, 25  0           ['conv2d_transpose_2[0][0]',     \n",
            "                                6)                                'activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 128, 128, 12  295040      ['concatenate_2[0][0]']          \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 128, 128, 12  512        ['conv2d_14[0][0]']              \n",
            " ormalization)                  8)                                                                \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 128, 128, 12  0           ['batch_normalization_14[0][0]'] \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 128, 128, 12  147584      ['activation_14[0][0]']          \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 128, 128, 12  512        ['conv2d_15[0][0]']              \n",
            " ormalization)                  8)                                                                \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 128, 128, 12  0           ['batch_normalization_15[0][0]'] \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_transpose_3 (Conv2DTran  (None, 256, 256, 64  32832      ['activation_15[0][0]']          \n",
            " spose)                         )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 256, 256, 12  0           ['conv2d_transpose_3[0][0]',     \n",
            "                                8)                                'activation_1[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 256, 256, 64  73792       ['concatenate_3[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 256, 256, 64  256        ['conv2d_16[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 256, 256, 64  0           ['batch_normalization_16[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 256, 256, 64  36928       ['activation_16[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 256, 256, 64  256        ['conv2d_17[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, 256, 256, 64  0           ['batch_normalization_17[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 256, 256, 1)  65          ['activation_17[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 31,055,297\n",
            "Trainable params: 31,043,521\n",
            "Non-trainable params: 11,776\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    ModelCheckpoint(model_path, verbose=1, save_best_only=True),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-7, verbose=1),\n",
        "    CSVLogger(csv_path),\n",
        "    EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=False),\n",
        "]\n",
        "\n",
        "model.fit(\n",
        "    train_dataset,\n",
        "    epochs=num_epochs,\n",
        "    validation_data=valid_dataset,\n",
        "    callbacks=callbacks\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UfhKZ4uULIu",
        "outputId": "5ac0e0aa-f994-4ddd-b79c-0b2bf521c57b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "848/848 [==============================] - ETA: 0s - loss: 0.7243 - dice_coef: 0.2758\n",
            "Epoch 1: val_loss improved from inf to 0.80101, saving model to files/model.h5\n",
            "848/848 [==============================] - 708s 800ms/step - loss: 0.7243 - dice_coef: 0.2758 - val_loss: 0.8010 - val_dice_coef: 0.1990 - lr: 1.0000e-04\n",
            "Epoch 2/50\n",
            "848/848 [==============================] - ETA: 0s - loss: 0.6154 - dice_coef: 0.3847\n",
            "Epoch 2: val_loss improved from 0.80101 to 0.61698, saving model to files/model.h5\n",
            "848/848 [==============================] - 139s 164ms/step - loss: 0.6154 - dice_coef: 0.3847 - val_loss: 0.6170 - val_dice_coef: 0.3830 - lr: 1.0000e-04\n",
            "Epoch 3/50\n",
            "848/848 [==============================] - ETA: 0s - loss: 0.5654 - dice_coef: 0.4346\n",
            "Epoch 3: val_loss improved from 0.61698 to 0.55866, saving model to files/model.h5\n",
            "848/848 [==============================] - 139s 164ms/step - loss: 0.5654 - dice_coef: 0.4346 - val_loss: 0.5587 - val_dice_coef: 0.4413 - lr: 1.0000e-04\n",
            "Epoch 4/50\n",
            "848/848 [==============================] - ETA: 0s - loss: 0.5328 - dice_coef: 0.4672\n",
            "Epoch 4: val_loss did not improve from 0.55866\n",
            "848/848 [==============================] - 145s 170ms/step - loss: 0.5328 - dice_coef: 0.4672 - val_loss: 0.5770 - val_dice_coef: 0.4230 - lr: 1.0000e-04\n",
            "Epoch 5/50\n",
            "848/848 [==============================] - ETA: 0s - loss: 0.5062 - dice_coef: 0.4938\n",
            "Epoch 5: val_loss improved from 0.55866 to 0.51343, saving model to files/model.h5\n",
            "848/848 [==============================] - 139s 163ms/step - loss: 0.5062 - dice_coef: 0.4938 - val_loss: 0.5134 - val_dice_coef: 0.4866 - lr: 1.0000e-04\n",
            "Epoch 6/50\n",
            "848/848 [==============================] - ETA: 0s - loss: 0.4879 - dice_coef: 0.5121\n",
            "Epoch 6: val_loss did not improve from 0.51343\n",
            "848/848 [==============================] - 144s 170ms/step - loss: 0.4879 - dice_coef: 0.5121 - val_loss: 0.5264 - val_dice_coef: 0.4736 - lr: 1.0000e-04\n",
            "Epoch 7/50\n",
            "848/848 [==============================] - ETA: 0s - loss: 0.4704 - dice_coef: 0.5296\n",
            "Epoch 7: val_loss improved from 0.51343 to 0.47424, saving model to files/model.h5\n",
            "848/848 [==============================] - 146s 172ms/step - loss: 0.4704 - dice_coef: 0.5296 - val_loss: 0.4742 - val_dice_coef: 0.5258 - lr: 1.0000e-04\n",
            "Epoch 8/50\n",
            "848/848 [==============================] - ETA: 0s - loss: 0.4638 - dice_coef: 0.5361\n",
            "Epoch 8: val_loss did not improve from 0.47424\n",
            "848/848 [==============================] - 145s 171ms/step - loss: 0.4638 - dice_coef: 0.5361 - val_loss: 0.5205 - val_dice_coef: 0.4795 - lr: 1.0000e-04\n",
            "Epoch 9/50\n",
            "848/848 [==============================] - ETA: 0s - loss: 0.4537 - dice_coef: 0.5463\n",
            "Epoch 9: val_loss improved from 0.47424 to 0.47179, saving model to files/model.h5\n",
            "848/848 [==============================] - 139s 163ms/step - loss: 0.4537 - dice_coef: 0.5463 - val_loss: 0.4718 - val_dice_coef: 0.5282 - lr: 1.0000e-04\n",
            "Epoch 10/50\n",
            "848/848 [==============================] - ETA: 0s - loss: 0.4457 - dice_coef: 0.5543\n",
            "Epoch 10: val_loss improved from 0.47179 to 0.45540, saving model to files/model.h5\n",
            "848/848 [==============================] - 146s 172ms/step - loss: 0.4457 - dice_coef: 0.5543 - val_loss: 0.4554 - val_dice_coef: 0.5446 - lr: 1.0000e-04\n",
            "Epoch 11/50\n",
            "848/848 [==============================] - ETA: 0s - loss: 0.4456 - dice_coef: 0.5544\n",
            "Epoch 11: val_loss did not improve from 0.45540\n",
            "848/848 [==============================] - 138s 162ms/step - loss: 0.4456 - dice_coef: 0.5544 - val_loss: 0.4720 - val_dice_coef: 0.5280 - lr: 1.0000e-04\n",
            "Epoch 12/50\n",
            "848/848 [==============================] - ETA: 0s - loss: 0.4413 - dice_coef: 0.5587\n",
            "Epoch 12: val_loss improved from 0.45540 to 0.44780, saving model to files/model.h5\n",
            "848/848 [==============================] - 147s 174ms/step - loss: 0.4413 - dice_coef: 0.5587 - val_loss: 0.4478 - val_dice_coef: 0.5522 - lr: 1.0000e-04\n",
            "Epoch 13/50\n",
            "848/848 [==============================] - ETA: 0s - loss: 0.4365 - dice_coef: 0.5635\n",
            "Epoch 13: val_loss did not improve from 0.44780\n",
            "848/848 [==============================] - 145s 171ms/step - loss: 0.4365 - dice_coef: 0.5635 - val_loss: 0.4979 - val_dice_coef: 0.5021 - lr: 1.0000e-04\n",
            "Epoch 14/50\n",
            "848/848 [==============================] - ETA: 0s - loss: 0.4371 - dice_coef: 0.5629\n",
            "Epoch 14: val_loss improved from 0.44780 to 0.44519, saving model to files/model.h5\n",
            "848/848 [==============================] - 147s 173ms/step - loss: 0.4371 - dice_coef: 0.5629 - val_loss: 0.4452 - val_dice_coef: 0.5548 - lr: 1.0000e-04\n",
            "Epoch 15/50\n",
            "848/848 [==============================] - ETA: 0s - loss: 0.4283 - dice_coef: 0.5717\n",
            "Epoch 15: val_loss improved from 0.44519 to 0.43743, saving model to files/model.h5\n",
            "848/848 [==============================] - 146s 172ms/step - loss: 0.4283 - dice_coef: 0.5717 - val_loss: 0.4374 - val_dice_coef: 0.5626 - lr: 1.0000e-04\n",
            "Epoch 16/50\n",
            "848/848 [==============================] - ETA: 0s - loss: 0.4303 - dice_coef: 0.5697\n",
            "Epoch 16: val_loss did not improve from 0.43743\n",
            "848/848 [==============================] - 145s 171ms/step - loss: 0.4303 - dice_coef: 0.5697 - val_loss: 0.4418 - val_dice_coef: 0.5582 - lr: 1.0000e-04\n",
            "Epoch 17/50\n",
            "848/848 [==============================] - ETA: 0s - loss: 0.4274 - dice_coef: 0.5726\n",
            "Epoch 17: val_loss did not improve from 0.43743\n",
            "848/848 [==============================] - 145s 171ms/step - loss: 0.4274 - dice_coef: 0.5726 - val_loss: 0.4394 - val_dice_coef: 0.5606 - lr: 1.0000e-04\n",
            "Epoch 18/50\n",
            "848/848 [==============================] - ETA: 0s - loss: 0.4252 - dice_coef: 0.5748\n",
            "Epoch 18: val_loss did not improve from 0.43743\n",
            "848/848 [==============================] - 145s 171ms/step - loss: 0.4252 - dice_coef: 0.5748 - val_loss: 0.5673 - val_dice_coef: 0.4327 - lr: 1.0000e-04\n",
            "Epoch 19/50\n",
            "848/848 [==============================] - ETA: 0s - loss: 0.4271 - dice_coef: 0.5729\n",
            "Epoch 19: val_loss did not improve from 0.43743\n",
            "848/848 [==============================] - 138s 162ms/step - loss: 0.4271 - dice_coef: 0.5729 - val_loss: 0.4448 - val_dice_coef: 0.5552 - lr: 1.0000e-04\n",
            "Epoch 20/50\n",
            "848/848 [==============================] - ETA: 0s - loss: 0.4232 - dice_coef: 0.5768\n",
            "Epoch 20: val_loss improved from 0.43743 to 0.43237, saving model to files/model.h5\n",
            "848/848 [==============================] - 140s 165ms/step - loss: 0.4232 - dice_coef: 0.5768 - val_loss: 0.4324 - val_dice_coef: 0.5676 - lr: 1.0000e-04\n",
            "Epoch 21/50\n",
            "848/848 [==============================] - ETA: 0s - loss: 0.4180 - dice_coef: 0.5820\n",
            "Epoch 21: val_loss did not improve from 0.43237\n",
            "848/848 [==============================] - 145s 171ms/step - loss: 0.4180 - dice_coef: 0.5820 - val_loss: 0.4366 - val_dice_coef: 0.5634 - lr: 1.0000e-04\n",
            "Epoch 22/50\n",
            "848/848 [==============================] - ETA: 0s - loss: 0.4254 - dice_coef: 0.5746\n",
            "Epoch 22: val_loss did not improve from 0.43237\n",
            "848/848 [==============================] - 145s 171ms/step - loss: 0.4254 - dice_coef: 0.5746 - val_loss: 0.4328 - val_dice_coef: 0.5672 - lr: 1.0000e-04\n",
            "Epoch 23/50\n",
            "848/848 [==============================] - ETA: 0s - loss: 0.4189 - dice_coef: 0.5811\n",
            "Epoch 23: val_loss did not improve from 0.43237\n",
            "848/848 [==============================] - 145s 171ms/step - loss: 0.4189 - dice_coef: 0.5811 - val_loss: 0.5122 - val_dice_coef: 0.4878 - lr: 1.0000e-04\n",
            "Epoch 24/50\n",
            "848/848 [==============================] - ETA: 0s - loss: 0.4206 - dice_coef: 0.5794\n",
            "Epoch 24: val_loss did not improve from 0.43237\n",
            "848/848 [==============================] - 145s 171ms/step - loss: 0.4206 - dice_coef: 0.5794 - val_loss: 0.4595 - val_dice_coef: 0.5405 - lr: 1.0000e-04\n",
            "Epoch 25/50\n",
            "848/848 [==============================] - ETA: 0s - loss: 0.4170 - dice_coef: 0.5830\n",
            "Epoch 25: val_loss improved from 0.43237 to 0.43177, saving model to files/model.h5\n",
            "848/848 [==============================] - 142s 167ms/step - loss: 0.4170 - dice_coef: 0.5830 - val_loss: 0.4318 - val_dice_coef: 0.5682 - lr: 1.0000e-04\n",
            "Epoch 26/50\n",
            "848/848 [==============================] - ETA: 0s - loss: 0.4161 - dice_coef: 0.5839\n",
            "Epoch 26: val_loss improved from 0.43177 to 0.42681, saving model to files/model.h5\n",
            "848/848 [==============================] - 142s 167ms/step - loss: 0.4161 - dice_coef: 0.5839 - val_loss: 0.4268 - val_dice_coef: 0.5732 - lr: 1.0000e-04\n",
            "Epoch 27/50\n",
            "848/848 [==============================] - ETA: 0s - loss: 0.4167 - dice_coef: 0.5833\n",
            "Epoch 27: val_loss did not improve from 0.42681\n",
            "848/848 [==============================] - 138s 163ms/step - loss: 0.4167 - dice_coef: 0.5833 - val_loss: 0.4347 - val_dice_coef: 0.5653 - lr: 1.0000e-04\n",
            "Epoch 28/50\n",
            "848/848 [==============================] - ETA: 0s - loss: 0.4132 - dice_coef: 0.5868\n",
            "Epoch 28: val_loss did not improve from 0.42681\n",
            "848/848 [==============================] - 138s 163ms/step - loss: 0.4132 - dice_coef: 0.5868 - val_loss: 0.4413 - val_dice_coef: 0.5587 - lr: 1.0000e-04\n",
            "Epoch 29/50\n",
            "848/848 [==============================] - ETA: 0s - loss: 0.4181 - dice_coef: 0.5819\n",
            "Epoch 29: val_loss did not improve from 0.42681\n",
            "848/848 [==============================] - 138s 163ms/step - loss: 0.4181 - dice_coef: 0.5819 - val_loss: 0.4307 - val_dice_coef: 0.5693 - lr: 1.0000e-04\n",
            "Epoch 30/50\n",
            "848/848 [==============================] - ETA: 0s - loss: 0.4129 - dice_coef: 0.5871\n",
            "Epoch 30: val_loss improved from 0.42681 to 0.42479, saving model to files/model.h5\n",
            "848/848 [==============================] - 151s 178ms/step - loss: 0.4129 - dice_coef: 0.5871 - val_loss: 0.4248 - val_dice_coef: 0.5752 - lr: 1.0000e-04\n",
            "Epoch 31/50\n",
            "848/848 [==============================] - ETA: 0s - loss: 0.4101 - dice_coef: 0.5899\n",
            "Epoch 31: val_loss improved from 0.42479 to 0.42086, saving model to files/model.h5\n",
            "848/848 [==============================] - 147s 173ms/step - loss: 0.4101 - dice_coef: 0.5899 - val_loss: 0.4209 - val_dice_coef: 0.5791 - lr: 1.0000e-04\n",
            "Epoch 32/50\n",
            "848/848 [==============================] - ETA: 0s - loss: 0.4109 - dice_coef: 0.5891\n",
            "Epoch 32: val_loss did not improve from 0.42086\n",
            "848/848 [==============================] - 145s 171ms/step - loss: 0.4109 - dice_coef: 0.5891 - val_loss: 0.4214 - val_dice_coef: 0.5786 - lr: 1.0000e-04\n",
            "Epoch 33/50\n",
            "848/848 [==============================] - ETA: 0s - loss: 0.4118 - dice_coef: 0.5882\n",
            "Epoch 33: val_loss did not improve from 0.42086\n",
            "848/848 [==============================] - 145s 171ms/step - loss: 0.4118 - dice_coef: 0.5882 - val_loss: 0.4269 - val_dice_coef: 0.5731 - lr: 1.0000e-04\n",
            "Epoch 34/50\n",
            "848/848 [==============================] - ETA: 0s - loss: 0.4153 - dice_coef: 0.5848\n",
            "Epoch 34: val_loss did not improve from 0.42086\n",
            "848/848 [==============================] - 138s 163ms/step - loss: 0.4153 - dice_coef: 0.5848 - val_loss: 0.4257 - val_dice_coef: 0.5743 - lr: 1.0000e-04\n",
            "Epoch 35/50\n",
            "848/848 [==============================] - ETA: 0s - loss: 0.4082 - dice_coef: 0.5918\n",
            "Epoch 35: val_loss did not improve from 0.42086\n",
            "848/848 [==============================] - 138s 163ms/step - loss: 0.4082 - dice_coef: 0.5918 - val_loss: 0.4216 - val_dice_coef: 0.5784 - lr: 1.0000e-04\n",
            "Epoch 36/50\n",
            "848/848 [==============================] - ETA: 0s - loss: 0.4103 - dice_coef: 0.5898\n",
            "Epoch 36: val_loss did not improve from 0.42086\n",
            "\n",
            "Epoch 36: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
            "848/848 [==============================] - 138s 163ms/step - loss: 0.4103 - dice_coef: 0.5898 - val_loss: 0.4414 - val_dice_coef: 0.5586 - lr: 1.0000e-04\n",
            "Epoch 37/50\n",
            "848/848 [==============================] - ETA: 0s - loss: 0.4089 - dice_coef: 0.5911\n",
            "Epoch 37: val_loss improved from 0.42086 to 0.42036, saving model to files/model.h5\n",
            "848/848 [==============================] - 147s 173ms/step - loss: 0.4089 - dice_coef: 0.5911 - val_loss: 0.4204 - val_dice_coef: 0.5796 - lr: 1.0000e-05\n",
            "Epoch 38/50\n",
            "848/848 [==============================] - ETA: 0s - loss: 0.4063 - dice_coef: 0.5937\n",
            "Epoch 38: val_loss improved from 0.42036 to 0.41950, saving model to files/model.h5\n",
            "848/848 [==============================] - 146s 173ms/step - loss: 0.4063 - dice_coef: 0.5937 - val_loss: 0.4195 - val_dice_coef: 0.5805 - lr: 1.0000e-05\n",
            "Epoch 39/50\n",
            "848/848 [==============================] - ETA: 0s - loss: 0.4055 - dice_coef: 0.5945\n",
            "Epoch 39: val_loss improved from 0.41950 to 0.41905, saving model to files/model.h5\n",
            "848/848 [==============================] - 147s 173ms/step - loss: 0.4055 - dice_coef: 0.5945 - val_loss: 0.4190 - val_dice_coef: 0.5810 - lr: 1.0000e-05\n",
            "Epoch 40/50\n",
            "848/848 [==============================] - ETA: 0s - loss: 0.4050 - dice_coef: 0.5951\n",
            "Epoch 40: val_loss improved from 0.41905 to 0.41842, saving model to files/model.h5\n",
            "848/848 [==============================] - 139s 164ms/step - loss: 0.4050 - dice_coef: 0.5951 - val_loss: 0.4184 - val_dice_coef: 0.5816 - lr: 1.0000e-05\n",
            "Epoch 41/50\n",
            "848/848 [==============================] - ETA: 0s - loss: 0.4045 - dice_coef: 0.5955\n",
            "Epoch 41: val_loss did not improve from 0.41842\n",
            "848/848 [==============================] - 138s 162ms/step - loss: 0.4045 - dice_coef: 0.5955 - val_loss: 0.4186 - val_dice_coef: 0.5814 - lr: 1.0000e-05\n",
            "Epoch 42/50\n",
            "848/848 [==============================] - ETA: 0s - loss: 0.4041 - dice_coef: 0.5959\n",
            "Epoch 42: val_loss did not improve from 0.41842\n",
            "848/848 [==============================] - 145s 171ms/step - loss: 0.4041 - dice_coef: 0.5959 - val_loss: 0.4187 - val_dice_coef: 0.5813 - lr: 1.0000e-05\n",
            "Epoch 43/50\n",
            "848/848 [==============================] - ETA: 0s - loss: 0.4036 - dice_coef: 0.5964\n",
            "Epoch 43: val_loss improved from 0.41842 to 0.41825, saving model to files/model.h5\n",
            "848/848 [==============================] - 142s 168ms/step - loss: 0.4036 - dice_coef: 0.5964 - val_loss: 0.4183 - val_dice_coef: 0.5817 - lr: 1.0000e-05\n",
            "Epoch 44/50\n",
            "848/848 [==============================] - ETA: 0s - loss: 0.4033 - dice_coef: 0.5968\n",
            "Epoch 44: val_loss did not improve from 0.41825\n",
            "848/848 [==============================] - 145s 170ms/step - loss: 0.4033 - dice_coef: 0.5968 - val_loss: 0.4183 - val_dice_coef: 0.5817 - lr: 1.0000e-05\n",
            "Epoch 45/50\n",
            "848/848 [==============================] - ETA: 0s - loss: 0.4029 - dice_coef: 0.5971\n",
            "Epoch 45: val_loss improved from 0.41825 to 0.41801, saving model to files/model.h5\n",
            "848/848 [==============================] - 140s 165ms/step - loss: 0.4029 - dice_coef: 0.5971 - val_loss: 0.4180 - val_dice_coef: 0.5820 - lr: 1.0000e-05\n",
            "Epoch 46/50\n",
            "848/848 [==============================] - ETA: 0s - loss: 0.4027 - dice_coef: 0.5973\n",
            "Epoch 46: val_loss improved from 0.41801 to 0.41787, saving model to files/model.h5\n",
            "848/848 [==============================] - 139s 163ms/step - loss: 0.4027 - dice_coef: 0.5973 - val_loss: 0.4179 - val_dice_coef: 0.5821 - lr: 1.0000e-05\n",
            "Epoch 47/50\n",
            "848/848 [==============================] - ETA: 0s - loss: 0.4024 - dice_coef: 0.5976\n",
            "Epoch 47: val_loss improved from 0.41787 to 0.41758, saving model to files/model.h5\n",
            "848/848 [==============================] - 139s 164ms/step - loss: 0.4024 - dice_coef: 0.5976 - val_loss: 0.4176 - val_dice_coef: 0.5824 - lr: 1.0000e-05\n",
            "Epoch 48/50\n",
            "848/848 [==============================] - ETA: 0s - loss: 0.4022 - dice_coef: 0.5978\n",
            "Epoch 48: val_loss did not improve from 0.41758\n",
            "848/848 [==============================] - 138s 163ms/step - loss: 0.4022 - dice_coef: 0.5978 - val_loss: 0.4180 - val_dice_coef: 0.5820 - lr: 1.0000e-05\n",
            "Epoch 49/50\n",
            "848/848 [==============================] - ETA: 0s - loss: 0.4020 - dice_coef: 0.5980\n",
            "Epoch 49: val_loss did not improve from 0.41758\n",
            "848/848 [==============================] - 137s 162ms/step - loss: 0.4020 - dice_coef: 0.5980 - val_loss: 0.4177 - val_dice_coef: 0.5823 - lr: 1.0000e-05\n",
            "Epoch 50/50\n",
            "848/848 [==============================] - ETA: 0s - loss: 0.4017 - dice_coef: 0.5983\n",
            "Epoch 50: val_loss did not improve from 0.41758\n",
            "848/848 [==============================] - 138s 162ms/step - loss: 0.4017 - dice_coef: 0.5983 - val_loss: 0.4180 - val_dice_coef: 0.5820 - lr: 1.0000e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f11bf7de650>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_results(image, mask, y_pred, save_image_path):\n",
        "    mask = np.expand_dims(mask, axis=-1)\n",
        "    mask = np.concatenate([mask, mask, mask], axis=-1)\n",
        "\n",
        "    y_pred = np.expand_dims(y_pred, axis=-1)\n",
        "    y_pred = np.concatenate([y_pred, y_pred, y_pred], axis=-1)\n",
        "    y_pred = y_pred * 255\n",
        "\n",
        "    line = np.ones((H, 10, 3)) * 255\n",
        "\n",
        "    cat_images = np.concatenate([image, line, mask, line, y_pred], axis=1)\n",
        "    cv2.imwrite(save_image_path, cat_images)\n",
        "  \n",
        "\"\"\" Directory for storing files \"\"\"\n",
        "create_dir(\"results\")\n",
        "\n",
        "\"\"\" Load the model \"\"\"\n",
        "with CustomObjectScope({\"dice_coef\": dice_coef, \"dice_loss\": dice_loss}):\n",
        "    model = tf.keras.models.load_model(os.path.join(\"files\", \"model.h5\"))\n",
        "\n",
        "\"\"\" Prediction and Evaluation \"\"\"\n",
        "SCORE = []\n",
        "for x, y in tqdm(zip(test_x, test_y), total=len(test_y)):\n",
        "    \"\"\" Extracting the name \"\"\"\n",
        "    name = x.split(\"/\")[-1]\n",
        "\n",
        "    \"\"\" Reading the image \"\"\"\n",
        "    image = cv2.imread(x, cv2.IMREAD_COLOR) ## [H, w, 3]\n",
        "    image = cv2.resize(image, (W, H))       ## [H, w, 3]\n",
        "    x = image/255.0                         ## [H, w, 3]\n",
        "    x = np.expand_dims(x, axis=0)           ## [1, H, w, 3]\n",
        "\n",
        "    \"\"\" Reading the mask \"\"\"\n",
        "    mask = cv2.imread(y, cv2.IMREAD_GRAYSCALE)\n",
        "    mask = cv2.resize(mask, (W, H))\n",
        "\n",
        "    \"\"\" Prediction \"\"\"\n",
        "    y_pred = model.predict(x, verbose=0)[0]\n",
        "    y_pred = np.squeeze(y_pred, axis=-1)\n",
        "    y_pred = y_pred >= 0.5\n",
        "    y_pred = y_pred.astype(np.int32)\n",
        "\n",
        "    \"\"\" Saving the prediction \"\"\"\n",
        "    save_image_path = os.path.join(\"results\", name)\n",
        "    save_results(image, mask, y_pred, save_image_path)\n",
        "\n",
        "    \"\"\" Flatten the array \"\"\"\n",
        "    mask = mask/255.0\n",
        "    mask = (mask > 0.5).astype(np.int32).flatten()\n",
        "    y_pred = y_pred.flatten()\n",
        "\n",
        "    \"\"\" Calculating the metrics values \"\"\"\n",
        "    f1_value = f1_score(mask, y_pred, labels=[0, 1], average=\"binary\")\n",
        "    jac_value = jaccard_score(mask, y_pred, labels=[0, 1], average=\"binary\")\n",
        "    recall_value = recall_score(mask, y_pred, labels=[0, 1], average=\"binary\", zero_division=0)\n",
        "    precision_value = precision_score(mask, y_pred, labels=[0, 1], average=\"binary\", zero_division=0)\n",
        "    SCORE.append([name, f1_value, jac_value, recall_value, precision_value])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVnOfO30UvEB",
        "outputId": "01ada569-6a99-4423-ae75-9a949799ed78"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  3%|▎         | 16/564 [00:07<03:53,  2.35it/s]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Jaccard is ill-defined and being set to 0.0 due to no true or predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "  5%|▍         | 28/564 [00:12<03:42,  2.41it/s]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Jaccard is ill-defined and being set to 0.0 due to no true or predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            " 14%|█▍        | 80/564 [00:34<03:21,  2.40it/s]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Jaccard is ill-defined and being set to 0.0 due to no true or predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            " 20%|██        | 115/564 [00:49<03:11,  2.34it/s]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Jaccard is ill-defined and being set to 0.0 due to no true or predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            " 21%|██        | 116/564 [00:50<03:13,  2.31it/s]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Jaccard is ill-defined and being set to 0.0 due to no true or predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            " 22%|██▏       | 122/564 [00:52<03:01,  2.43it/s]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Jaccard is ill-defined and being set to 0.0 due to no true or predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            " 24%|██▎       | 133/564 [00:57<03:00,  2.39it/s]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Jaccard is ill-defined and being set to 0.0 due to no true or predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            " 27%|██▋       | 154/564 [01:06<03:05,  2.21it/s]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Jaccard is ill-defined and being set to 0.0 due to no true or predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            " 28%|██▊       | 156/564 [01:07<03:14,  2.10it/s]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Jaccard is ill-defined and being set to 0.0 due to no true or predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            " 33%|███▎      | 187/564 [01:20<02:56,  2.14it/s]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Jaccard is ill-defined and being set to 0.0 due to no true or predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            " 37%|███▋      | 207/564 [01:28<02:25,  2.45it/s]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Jaccard is ill-defined and being set to 0.0 due to no true or predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            " 38%|███▊      | 217/564 [01:33<02:33,  2.26it/s]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Jaccard is ill-defined and being set to 0.0 due to no true or predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            " 40%|███▉      | 223/564 [01:35<02:17,  2.48it/s]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Jaccard is ill-defined and being set to 0.0 due to no true or predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            " 47%|████▋     | 267/564 [01:54<02:07,  2.34it/s]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Jaccard is ill-defined and being set to 0.0 due to no true or predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            " 48%|████▊     | 268/564 [01:54<02:03,  2.40it/s]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Jaccard is ill-defined and being set to 0.0 due to no true or predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            " 49%|████▊     | 274/564 [01:57<02:16,  2.13it/s]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Jaccard is ill-defined and being set to 0.0 due to no true or predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            " 51%|█████▏    | 290/564 [02:04<02:05,  2.19it/s]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Jaccard is ill-defined and being set to 0.0 due to no true or predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            " 53%|█████▎    | 299/564 [02:08<01:45,  2.51it/s]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Jaccard is ill-defined and being set to 0.0 due to no true or predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            " 54%|█████▍    | 305/564 [02:11<01:58,  2.19it/s]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Jaccard is ill-defined and being set to 0.0 due to no true or predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            " 61%|██████    | 342/564 [02:27<01:34,  2.34it/s]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Jaccard is ill-defined and being set to 0.0 due to no true or predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            " 77%|███████▋  | 433/564 [03:06<00:55,  2.35it/s]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Jaccard is ill-defined and being set to 0.0 due to no true or predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            " 86%|████████▌ | 486/564 [03:28<00:32,  2.37it/s]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Jaccard is ill-defined and being set to 0.0 due to no true or predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            " 87%|████████▋ | 490/564 [03:30<00:30,  2.39it/s]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Jaccard is ill-defined and being set to 0.0 due to no true or predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            " 93%|█████████▎| 522/564 [03:44<00:17,  2.43it/s]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Jaccard is ill-defined and being set to 0.0 due to no true or predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            " 93%|█████████▎| 524/564 [03:45<00:16,  2.45it/s]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Jaccard is ill-defined and being set to 0.0 due to no true or predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            " 94%|█████████▍| 529/564 [03:47<00:14,  2.47it/s]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Jaccard is ill-defined and being set to 0.0 due to no true or predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            " 96%|█████████▌| 539/564 [03:51<00:12,  2.00it/s]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Jaccard is ill-defined and being set to 0.0 due to no true or predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            " 96%|█████████▌| 541/564 [03:52<00:10,  2.14it/s]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Jaccard is ill-defined and being set to 0.0 due to no true or predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            " 97%|█████████▋| 549/564 [03:55<00:06,  2.47it/s]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Jaccard is ill-defined and being set to 0.0 due to no true or predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "100%|██████████| 564/564 [04:02<00:00,  2.33it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Metrics values \"\"\"\n",
        "score = [s[1:]for s in SCORE]\n",
        "score = np.mean(score, axis=0)\n",
        "print(f\"F1: {score[0]:0.5f}\")\n",
        "print(f\"Jaccard: {score[1]:0.5f}\")\n",
        "print(f\"Recall: {score[2]:0.5f}\")\n",
        "print(f\"Precision: {score[3]:0.5f}\")\n",
        "\n",
        "df = pd.DataFrame(SCORE, columns=[\"Image\", \"F1\", \"Jaccard\", \"Recall\", \"Precision\"])\n",
        "df.to_csv(\"files/score.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YgjMIG9ZW3mT",
        "outputId": "a4c39e71-f7d9-4086-d9de-4a7ddc592625"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1: 0.77143\n",
            "Jaccard: 0.71208\n",
            "Recall: 0.82750\n",
            "Precision: 0.74526\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}